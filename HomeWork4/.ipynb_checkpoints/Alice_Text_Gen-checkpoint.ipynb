{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N-5I8cWjqBOm",
   "metadata": {
    "id": "N-5I8cWjqBOm"
   },
   "outputs": [],
   "source": [
    "# Tải các file thư viện dữ liệu cần thiết\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2580c",
   "metadata": {
    "id": "ffa2580c"
   },
   "source": [
    "Trong bài toán này ta sẽ nhận dữ liệu là cuốn truyện \"Alice ở xứ sở thần tiên\" được cung cấp dưới dạng ASCII lưu trong file \"wonderland.txt\", ta sẽ học cách sinh ra một kí tự dựa vào một chuỗi kí tự phía trước của nó. Từ việc sinh ra 1 kí tự, kết hợp ta sinh ra một đoạn văn bản từ những chuỗi kí tự ban đầu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88650ccc",
   "metadata": {
    "id": "88650ccc"
   },
   "outputs": [],
   "source": [
    "# Chúng ta sẽ load bộ dữ liệu dưới dạng ASCII\n",
    "# Vì chúng ta quan tâm tới chỉ là dữ liệu dạng các kí tự,\n",
    "# nên để cho đơn giản ta sẽ chuyển hết các dạng kí tự \n",
    "# về kí tự viết thường nhờ lệnh \"lower()\"\n",
    "filename = \"/home/namanh/DHBK_AI_ML_DL/Course/Day9/Course4/data/wonderland.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e097ca",
   "metadata": {
    "id": "32e097ca"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "# Vì chúng ta chỉ làm việc với dữ liệu dạng số học\n",
    "# nên để giải quyết bài toán chúng ta sẽ tạo ra 1 list các kí tự\n",
    "# có trong văn bản và tạo ra 1 map để kết nối từng kí tự với số của chúng.\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf79d2",
   "metadata": {
    "id": "bdaf79d2",
    "outputId": "7713395a-d25f-4537-dabc-6db81ad1abff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144512\n",
      "Total Vocab:  45\n"
     ]
    }
   ],
   "source": [
    "# Tóm tắt lại việc xử lí data đầu vào\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6a4fd",
   "metadata": {
    "id": "5dc6a4fd"
   },
   "source": [
    "Nhận thấy rằng chúng ta có gần 150,000 kí tự khi đã chuyển về dạng kí tự viết thường. Chỉ có 45 kí tự phân biệt, nhiều hơn so với chuẩn bản chữ cái tiếng Anh chỉ có 26 chữ cái. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679b4a6",
   "metadata": {
    "id": "4679b4a6",
    "outputId": "de2c375b-41f3-4d78-f899-41c2347a11cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144412\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "# Ta sẽ chia cuốn sách thành các chuỗi kí tự có độ dai 100 (có thể thay đổi)\n",
    "# Vì vậy đầu vào mạng sẽ là 100 kí tự để đoán đầu ra là 1 kí tự \n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f116892",
   "metadata": {
    "id": "8f116892"
   },
   "outputs": [],
   "source": [
    "# Chuyển dạng dữ liêụ đầu vào về dạng [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize để cho mang lstm dễ học vì nó khá nhạy cảm với số liệu\n",
    "# đặc biệt khi dùng hàm kích hoạt là signmoid hay tanh\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable cho việc dự đoán \n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3914ed9",
   "metadata": {
    "id": "d3914ed9",
    "outputId": "77ec5275-9cf5-4d38-9d21-b4884f5d3d8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-25 13:44:18.836112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-25 13:44:18.894376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-25 13:44:18.900575: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-25 13:44:18.901915: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# tạo nên 1 mô hình LSTM \n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c03975",
   "metadata": {
    "id": "60c03975"
   },
   "outputs": [],
   "source": [
    "# tạo nên các file checkpoint lưu việc training \n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e74c1",
   "metadata": {
    "id": "df3e74c1",
    "outputId": "2a2e81d4-2500-4f8c-f3e0-4ab60067aedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1129/1129 [==============================] - 742s 656ms/step - loss: 2.8218\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.82175, saving model to weights-improvement-01-2.8218.hdf5\n",
      "Epoch 2/20\n",
      "1129/1129 [==============================] - 767s 680ms/step - loss: 2.4906\n",
      "\n",
      "Epoch 00002: loss improved from 2.82175 to 2.49057, saving model to weights-improvement-02-2.4906.hdf5\n",
      "Epoch 3/20\n",
      "1129/1129 [==============================] - 791s 701ms/step - loss: 2.2897\n",
      "\n",
      "Epoch 00003: loss improved from 2.49057 to 2.28972, saving model to weights-improvement-03-2.2897.hdf5\n",
      "Epoch 4/20\n",
      "1129/1129 [==============================] - 767s 679ms/step - loss: 2.1564\n",
      "\n",
      "Epoch 00004: loss improved from 2.28972 to 2.15642, saving model to weights-improvement-04-2.1564.hdf5\n",
      "Epoch 5/20\n",
      "1129/1129 [==============================] - 744s 659ms/step - loss: 2.0584\n",
      "\n",
      "Epoch 00005: loss improved from 2.15642 to 2.05835, saving model to weights-improvement-05-2.0584.hdf5\n",
      "Epoch 6/20\n",
      "1129/1129 [==============================] - 769s 681ms/step - loss: 1.9837\n",
      "\n",
      "Epoch 00006: loss improved from 2.05835 to 1.98372, saving model to weights-improvement-06-1.9837.hdf5\n",
      "Epoch 7/20\n",
      " 688/1129 [=================>............] - ETA: 4:58 - loss: 1.9162"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22486fb",
   "metadata": {
    "id": "a22486fb"
   },
   "outputs": [],
   "source": [
    "# load lại file trọng số đã lưu của mạng \n",
    "filename = \"weights-improvement-47-1.2219-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# lựa chọn seed ngẫu nhiên để tạo test \n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Alice_Text_Gen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
